{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cedf85-8125-4322-998e-9375fe745597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from openai import OpenAI\n",
    "from items import Item\n",
    "from loaders import ItemLoader\n",
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7390a6aa-79cb-4dea-b6d7-de7e4b13e472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6f1fb",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049885d4-fdfa-4ff0-a932-4a2ed73928e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Appliances\", split=\"full\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78435dfc",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde08860-b393-49b8-a620-06a8c0990a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Appliances: 94,327\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Appliances: {len(dataset):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e29a5ab-ca61-41cc-9b33-22d374681b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a4e10f-6710-4780-a95e-6c0030c3fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothes Dryer Drum Slide, General Electric, Hotpoint, WE1M333, WE1M504\n",
      "['Brand new dryer drum slide, replaces General Electric, Hotpoint, RCA, WE1M333, WE1M504.']\n",
      "[]\n",
      "{\"Manufacturer\": \"RPI\", \"Part Number\": \"WE1M333,\", \"Item Weight\": \"0.352 ounces\", \"Package Dimensions\": \"5.5 x 4.7 x 0.4 inches\", \"Item model number\": \"WE1M333,\", \"Is Discontinued By Manufacturer\": \"No\", \"Item Package Quantity\": \"1\", \"Batteries Included?\": \"No\", \"Batteries Required?\": \"No\", \"Best Sellers Rank\": {\"Tools & Home Improvement\": 1315213, \"Parts & Accessories\": 181194}, \"Date First Available\": \"February 25, 2014\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datapoint[\"title\"])\n",
    "print(datapoint[\"description\"])\n",
    "print(datapoint[\"features\"])\n",
    "print(datapoint[\"details\"])\n",
    "print(datapoint[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d356c6f-b6e8-4e01-98cd-c562d132aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many prices?\n",
    "\n",
    "prices = 0\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            prices += 1\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {prices:,} with prices which is {prices/len(dataset)*100:,.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd890259-aa25-4097-9524-f91c2bdd719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those with prices, gather the price and the length\n",
    "\n",
    "prices = []\n",
    "lengths = []\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            prices.append(price)\n",
    "            contents = datapoint[\"title\"] + str(datapoint[\"description\"]) + str(datapoint[\"features\"]) + str(datapoint[\"details\"])\n",
    "            lengths.append(len(contents))\n",
    "    except ValueError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89078cb1-9679-4eb0-b295-599b8586bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of lengths\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Lengths: Avg {sum(lengths)/len(lengths):,.0f} and highest {max(lengths):,}\\n\")\n",
    "plt.xlabel('Length (chars)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(lengths, rwidth=0.7, color=\"lightblue\", bins=range(0, 6000, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e0c43-9f7a-450e-a911-c94d37d9b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.2f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"orange\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d02f58-23f6-4f81-a779-7c0555afd13d",
   "metadata": {},
   "source": [
    "## Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b432f-b769-41da-9506-a238cb5cf1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Item object for each with a price\n",
    "\n",
    "items = []\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            item = Item(datapoint, price)\n",
    "            if item.include:\n",
    "                items.append(item)\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {len(items):,} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d570794-6f1d-462e-b567-a46bae3556a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70219e99-22cc-4e08-9121-51f9707caef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the prompt that will be used during training - the model learns to complete this\n",
    "\n",
    "print(items[100].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9998b8d-d746-4541-9ac2-701108e0e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the prompt that will be used during testing - the model has to complete this\n",
    "\n",
    "print(items[100].test_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a116369-335a-412b-b70c-2add6675c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of token counts\n",
    "\n",
    "tokens = [item.token_count for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
    "plt.xlabel('Length (tokens)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(tokens, rwidth=0.7, color=\"green\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1744aa-71e7-435e-876e-91f06583211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"purple\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the same dataset as last time, this time with ItemLoader\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "items = ItemLoader(\"Appliances\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22664fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for a familiar item...\n",
    "\n",
    "print(items[1].prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631e5bd",
   "metadata": {},
   "source": [
    "## Now Let's Scale Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"Automotive\",\n",
    "    \"Electronics\",\n",
    "    \"Office_Products\",\n",
    "    \"Tools_and_Home_Improvement\",\n",
    "    \"Cell_Phones_and_Accessories\",\n",
    "    \"Toys_and_Games\",\n",
    "    \"Appliances\",\n",
    "    \"Musical_Instruments\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for dataset_name in dataset_names:\n",
    "    loader = ItemLoader(dataset_name)\n",
    "    items.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A grand total of {len(items):,} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26707185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of token counts again\n",
    "\n",
    "tokens = [item.token_count for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
    "plt.xlabel('Length (tokens)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(tokens, rwidth=0.7, color=\"skyblue\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"blueviolet\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = Counter()\n",
    "for item in items:\n",
    "    category_counts[item.category]+=1\n",
    "\n",
    "categories = category_counts.keys()\n",
    "counts = [category_counts[category] for category in categories]\n",
    "\n",
    "# Bar chart by category\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(categories, counts, color=\"goldenrod\")\n",
    "plt.title('How many in each category')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(counts):\n",
    "    plt.text(i, v, f\"{v:,}\", ha='center', va='bottom')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e615b33",
   "metadata": {},
   "source": [
    "### Let's craft a dataset which is more balanced in terms of prices. Less heavily scewed to cheap items, with an average that's higher than $60. Try to balance out the categories - fewer Automotive items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with a key of each price from $1 to $999\n",
    "# And in the value, put a list of items with that price (to nearest round number)\n",
    "\n",
    "slots = defaultdict(list)\n",
    "for item in items:\n",
    "    slots[round(item.price)].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a54998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset called \"sample\" which tries to more evenly take from the range of prices\n",
    "# and gives more weight to items from categories other than Automotive\n",
    "# Set random seed for reproducibility\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "sample = []\n",
    "for i in range(1, 1000):\n",
    "    slot = slots[i]\n",
    "    if i>=240:\n",
    "        sample.extend(slot)\n",
    "    elif len(slot) <= 1200:\n",
    "        sample.extend(slot)\n",
    "    else:\n",
    "        weights = np.array([1 if item.category=='Automotive' else 5 for item in slot])\n",
    "        weights = weights / np.sum(weights)\n",
    "        selected_indices = np.random.choice(len(slot), size=1200, replace=False, p=weights)\n",
    "        selected = [slot[i] for i in selected_indices]\n",
    "        sample.extend(selected)\n",
    "\n",
    "print(f\"There are {len(sample):,} items in the sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c284a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices in sample\n",
    "\n",
    "prices = [float(item.price) for item in sample]\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe01cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, we did well in terms of raising the average price and having a smooth-ish population of prices\n",
    "# Let's see the categories\n",
    "\n",
    "category_counts = Counter()\n",
    "for item in sample:\n",
    "    category_counts[item.category]+=1\n",
    "\n",
    "categories = category_counts.keys()\n",
    "counts = [category_counts[category] for category in categories]\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(categories, counts, color=\"lightgreen\")\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('How many in each category')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(counts):\n",
    "    plt.text(i, v, f\"{v:,}\", ha='center', va='bottom')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.pie(counts, labels=categories, autopct='%1.0f%%', startangle=90)\n",
    "\n",
    "centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.title('Categories')\n",
    "\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674156a9",
   "metadata": {},
   "source": [
    "## Dataset Curated!\n",
    "### Let's do some final checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the price vary with the character count of the prompt?\n",
    "\n",
    "sizes = [len(item.prompt) for item in sample]\n",
    "prices = [item.price for item in sample]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(sizes, prices, s=0.2, color=\"red\")\n",
    "\n",
    "plt.xlabel('Size')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Is there a simple correlation?')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(item):\n",
    "    prompt = item.prompt\n",
    "    tokens = Item.tokenizer.encode(item.prompt)\n",
    "    print(prompt)\n",
    "    print(tokens[-10:])\n",
    "    print(Item.tokenizer.batch_decode(tokens[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(sample[398000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147fe73f",
   "metadata": {},
   "source": [
    "### It's time to break down our data into a training, test and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a855ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(sample)\n",
    "train = sample[:400_000]\n",
    "test = sample[400_000:402_000]\n",
    "print(f\"Divided into a training set of {len(train):,} items and test set of {len(test):,} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[0].test_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c302614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices in the first 250 test points\n",
    "\n",
    "prices = [float(item.price) for item in test[:250]]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361584d",
   "metadata": {},
   "source": [
    "### Upload your brand new dataset. Convert to prompts and upload to HuggingFace hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts = [item.prompt for item in train]\n",
    "train_prices = [item.price for item in train]\n",
    "test_prompts = [item.test_prompt() for item in test]\n",
    "test_prices = [item.price for item in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\"text\": train_prompts, \"price\": train_prices})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_prompts, \"price\": test_prices})\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pickle the training and test dataset so we don't have to execute all this code next time!\n",
    "\n",
    "with open('train.pkl', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "\n",
    "with open('test.pkl', 'wb') as file:\n",
    "    pickle.dump(test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f02119",
   "metadata": {},
   "source": [
    "### Work on some traditional ML models to act as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8318204",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = \"\\033[92m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "RED = \"\\033[91m\"\n",
    "RESET = \"\\033[0m\"\n",
    "COLOR_MAP = {\"red\":RED, \"orange\": YELLOW, \"green\": GREEN}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ca2f8",
   "metadata": {},
   "source": [
    "### Loading the pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f6978",
   "metadata": {},
   "source": [
    "### Let's start with a random number generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pricer(item):\n",
    "    return random.randrange(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "Tester.test(random_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now a model that predicts the average price\n",
    "\n",
    "training_prices = [item.price for item in train]\n",
    "training_average = sum(training_prices) / len(training_prices)\n",
    "\n",
    "def constant_pricer(item):\n",
    "    return training_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our constant predictor\n",
    "Tester.test(constant_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5197b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new \"features\" field on items, and populate it with json parsed from the details dict\n",
    "\n",
    "for item in train:\n",
    "    item.features = json.loads(item.details)\n",
    "for item in test:\n",
    "    item.features = json.loads(item.details)\n",
    "\n",
    "# Look at one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cf7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at 20 most common features in training set\n",
    "\n",
    "feature_count = Counter()\n",
    "for item in train:\n",
    "    for f in item.features.keys():\n",
    "        feature_count[f]+=1\n",
    "\n",
    "feature_count.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(item):\n",
    "    weight_str = item.features.get('Item Weight')\n",
    "    if weight_str:\n",
    "        parts = weight_str.split(' ')\n",
    "        amount = float(parts[0])\n",
    "        unit = parts[1].lower()\n",
    "        if unit==\"pounds\":\n",
    "            return amount\n",
    "        elif unit==\"ounces\":\n",
    "            return amount / 16\n",
    "        elif unit==\"grams\":\n",
    "            return amount / 453.592\n",
    "        elif unit==\"milligrams\":\n",
    "            return amount / 453592\n",
    "        elif unit==\"kilograms\":\n",
    "            return amount / 0.453592\n",
    "        elif unit==\"hundredths\" and parts[2].lower()==\"pounds\":\n",
    "            return amount / 100\n",
    "        else:\n",
    "            print(weight_str)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [get_weight(t) for t in train]\n",
    "weights = [w for w in weights if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_weight = sum(weights)/len(weights)\n",
    "average_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14036d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_with_default(item):\n",
    "    weight = get_weight(item)\n",
    "    return weight or average_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(item):\n",
    "    rank_dict = item.features.get(\"Best Sellers Rank\")\n",
    "    if rank_dict:\n",
    "        ranks = rank_dict.values()\n",
    "        return sum(ranks)/len(ranks)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72159ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [get_rank(t) for t in train]\n",
    "ranks = [r for r in ranks if r]\n",
    "average_rank = sum(ranks)/len(ranks)\n",
    "average_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9593d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_with_default(item):\n",
    "    rank = get_rank(item)\n",
    "    return rank or average_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length(item):\n",
    "    return len(item.test_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(item):\n",
    "    return item.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0].category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(item):\n",
    "    return {\n",
    "        \"weight\": get_weight_with_default(item),\n",
    "        \"rank\": get_rank_with_default(item),\n",
    "        \"text_length\": get_text_length(item),\n",
    "        \"category\": get_category(item)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at features in a training item\n",
    "get_features(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to convert our features into a pandas dataframe\n",
    "\n",
    "def list_to_dataframe(items):\n",
    "    features = [get_features(item) for item in items]\n",
    "    df = pd.DataFrame(features)\n",
    "    df = pd.get_dummies(df, columns=[\"category\"], dtype=int)\n",
    "    df['price'] = [item.price for item in items]\n",
    "    return df\n",
    "\n",
    "train_df = list_to_dataframe(train)\n",
    "test_df = list_to_dataframe(test[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Linear Regression!\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop(\"price\", axis=1)\n",
    "y_train = train_df[\"price\"]\n",
    "X_test = test_df.drop(\"price\", axis=1)\n",
    "y_test = test_df[\"price\"]\n",
    "\n",
    "# Train a Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "for feature, coef in zip(X_train.columns, model.coef_):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "# Predict the test set and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ae507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict price for a new item\n",
    "\n",
    "def linear_regression_pricer(item):\n",
    "    features = get_features(item)\n",
    "    category_list = [\"category_Appliances\", \"category_Automotive\", \"category_Cell_Phones_and_Accessories\",\n",
    "                     \"category_Electronics\", \"category_Musical_Instruments\", \"category_Office_Products\",\n",
    "                     \"category_Tools_and_Home_Improvement\", \"category_Toys_and_Games\"]\n",
    "    category_dict = dict(zip(category_list, [0]*len(category_list)))\n",
    "    category_dict[f\"category_{features['category']}\"] = 1\n",
    "    features.update(category_dict)\n",
    "    features_df = pd.DataFrame([features])\n",
    "    features_df.drop(\"category\", axis=1, inplace=True)\n",
    "    return model.predict(features_df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "\n",
    "Tester.test(linear_regression_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca973bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next few models, we prepare our documents and prices\n",
    "\n",
    "prices = np.array([float(item.price) for item in train])\n",
    "documents = [item.test_prompt() for item in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f225aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CountVectorizer for a Bag of Words model\n",
    "\n",
    "np.random.seed(42)\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15597163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_lr_pricer(item):\n",
    "    x = vectorizer.transform([item.test_prompt()])\n",
    "    return max(regressor.predict(x)[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "\n",
    "Tester.test(bow_lr_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d13ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The amazing word2vec model, implemented in gensim NLP library\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Preprocess the documents\n",
    "processed_docs = [simple_preprocess(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=processed_docs, vector_size=400, window=5, min_count=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step of averaging vectors across the document is a weakness in our approach\n",
    "\n",
    "def document_vector(doc):\n",
    "    doc_words = simple_preprocess(doc)\n",
    "    word_vectors = [w2v_model.wv[word] for word in doc_words if word in w2v_model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(w2v_model.vector_size)\n",
    "\n",
    "# Create feature matrix\n",
    "X_w2v = np.array([document_vector(doc) for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c62dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Linear Regression on word2vec\n",
    "\n",
    "word2vec_lr_regressor = LinearRegression()\n",
    "word2vec_lr_regressor.fit(X_w2v, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e37246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_lr_pricer(item):\n",
    "    doc = item.test_prompt()\n",
    "    doc_vector = document_vector(doc)\n",
    "    return max(0, word2vec_lr_regressor.predict([doc_vector])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(word2vec_lr_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "np.random.seed(42)\n",
    "svr_regressor = LinearSVR()\n",
    "\n",
    "svr_regressor.fit(X_w2v, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a102ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_pricer(item):\n",
    "    np.random.seed(42)\n",
    "    doc = item.test_prompt()\n",
    "    doc_vector = document_vector(doc)\n",
    "    return max(float(svr_regressor.predict([doc_vector])[0]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(svr_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the powerful Random Forest regression\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=8)\n",
    "rf_model.fit(X_w2v, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_pricer(item):\n",
    "    doc = item.test_prompt()\n",
    "    doc_vector = document_vector(doc)\n",
    "    return max(0, rf_model.predict([doc_vector])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(random_forest_pricer, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272df434",
   "metadata": {},
   "source": [
    "### Now to the LLM model that can estimate how much something costs, from its description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1650210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that I'm removing the \" to the nearest dollar\"\n",
    "# When we train our own models, we'll need to make the problem as easy as possible, \n",
    "# but a Frontier model needs no such simplification.\n",
    "\n",
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\", \"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to extract the price from a string\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price(\"The price is roughly $99.99 because blah blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12810365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_4o_mini(item):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=messages_for(item),\n",
    "        seed=42,\n",
    "        max_tokens=5\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f728893",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(gpt_4o_mini, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
